<!DOCTYPE html>
<html lang="en">
  <head>
  <title>TITLE</title>
  <meta name="description" content="DESCRIPTION" />
  <meta name="keywords" content="KEYWORD" />

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />

  <meta property="og:locale" content="ja_jp" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="SITE_TITLE" />
  <meta property="og:title" content="PAGE_TITLE" />
  <meta property="og:description" content="PAGE_DESCRIPTION" />
  <meta property="og:image" content="/images/common/img_ogp.png" />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="PAGE_TITLE" />
  <meta name="twitter:url" content="PAGE_URL" />
  <meta name="twitter:image" content="/images/common/img_ogp.png" />

  <link rel="stylesheet" href="css/app.css" />
  <!-- <script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script> -->
</head>

  <body>
    <!-- <header class="header">
  <h1>Orientation Demo</h1>
</header> -->


    <!-- 
      Create box parallax
      1: AFrame & Object model display
      2: Webcam & Tensorflow test <--here
      3: Create logic for parallax
     -->

    <!-- A-Frame -->
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>

    <!-- WebcamJS -->
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/webcamjs/1.0.26/webcam.min.js"
      integrity="sha512-dQIiHSl2hr3NWKKLycPndtpbh5iaHLo6MwrXm7F0FM5e+kL2U16oE9uIwPHUl6fQBeCthiEuV/rzP3MiAB8Vfw=="
      crossorigin="anonymous"
    ></script>

    <!-- Tensorflow -->
    <script src="https://unpkg.com/@tensorflow/tfjs-core@2.1.0/dist/tf-core.js"></script>
    <script src="https://unpkg.com/@tensorflow/tfjs-converter@2.1.0/dist/tf-converter.js"></script>
    <script src="https://unpkg.com/@tensorflow/tfjs-backend-webgl@2.1.0/dist/tf-backend-webgl.js"></script>

    <main>
      <video class="container"></video>
      <!-- <a-scene>
        <a-entity
          geometry="primitive: box; width: 1; height: 1; depth: 1"
          position="0 0 -1"
          material="color: #0000FF; opacity: 1; wireframe: true;"
          rotation="0 0 0"
        >
        </a-entity>
        <a-camera position="0 0 0"></a-camera>
      </a-scene> -->
    </main>

    <script>
      async function main() {
        // Load the MediaPipe facemesh model.
        const model = await facemesh.load()

        // Pass in a video stream (or an image, canvas, or 3D tensor) to obtain an
        // array of detected faces from the MediaPipe graph.
        const predictions = await model.estimateFaces(document.querySelector("video"))

        if (predictions.length > 0) {
          for (let i = 0; i < predictions.length; i++) {
            const keypoints = predictions[i].scaledMesh

            // Log facial keypoints.
            for (let i = 0; i < keypoints.length; i++) {
              const [x, y, z] = keypoints[i]

              console.log(`Keypoint ${i}: [${x}, ${y}, ${z}]`)
            }
          }
        }
      }

      main()
    </script>
  </body>
</html>
